#!/usr/bin/env python3
"""Module containing the class RNNCell that represents a cell of a simple
RNN."""

import numpy as np


class RNNCell():
    """Class that represents a cell of a simple RNN.
    """

    def __init__(self, i, h, o):
        """Class constructor creates the public instance attributes Wh, Wy,
        bh, by that represent the weights and biases of the cell. Wh and bh are
        for the concatenated hidden state and input data. Wy and by are for the
        output. The weights are initialized using a random normal distribution
        in the order listed previously. The weights will be used on the right
        side for matrix multiplication. The biases are initialized as zeros.

        Args:
            i (int): The dimensionality of the data.
            h (int): The dimensionality of the hidden state.
            o (int): The dimensionality of the outputs.
        """
        self.Wh = np.random.normal(size=(h + i, h))
        self.Wy = np.random.normal(size=(h, o))
        self.bh = np.zeros((1, h))
        self.by = np.zeros((1, o))

    def forward(self, h_prev, x_t):
        """Public instance method that performs forward propagation for one
        time step.

        Args:
            h_prev (numpy.ndarray): Tensor of shape (m, h) containing the
                previous hidden state,  where m is the batch size for the data
                and h is the dimensionality of the hidden state.
            x_t (numpy.ndarray): Tensor of shape (m, i) that contains the data
                input for the cell, where m is the batch size for the data and
                i is the dimensionality of the data.

        Returns:
            h_next (numpy.ndarray): Tensor of shape (m, h) containing the
                next hidden state,  where m is the batch size for the data
                and h is the dimensionality of the hidden state.
            y (numpy.ndarray): Tensor of shape (m, i) that contains the data
                output for the cell, where m is the batch size for the data and
                i is the dimensionality of the data.
        """
        m, h = h_prev.shape
        _, i = x_t.shape
        W_hh = self.Wh[:h, :]  # Shape = (h, h)
        W_hx = self.Wh[h:, :]  # Shape = (i, h)
        W_yh = self.Wy  # Shape = (h, o)
        b_h = self.bh
        b_y = self.by

        # h[t] = tanh(W_hh * h[t−1] + W_hx * x[t] + b_h)
        h_next = np.tanh((h_prev @ W_hh) + ((x_t @ W_hx) + b_h))
        # ŷ[t] = softmax(W_yh * h[t] + b_y)
        y = self.softmax((h_next @ W_yh) + b_y)
        return h_next, y

    def softmax(self, y):
        """Softmax activation function.

        Args:
            y (numpy.ndarray): A 2D tensor to apply the soft max activation on.

        Returns:
            The softmax activated version of y.
        """
        return np.exp(y) / (np.sum(np.exp(y), axis=1, keepdims=True))


# Testing
if __name__ == "__main__":
    np.random.seed(0)
    rnn_cell = RNNCell(10, 15, 5)
    print("Wh:", rnn_cell.Wh)
    print("Wy:", rnn_cell.Wy)
    print("bh:", rnn_cell.bh)
    print("by:", rnn_cell.by)
    rnn_cell.bh = np.random.randn(1, 15)
    rnn_cell.by = np.random.randn(1, 5)
    h_prev = np.random.randn(8, 15)
    x_t = np.random.randn(8, 10)
    h, y = rnn_cell.forward(h_prev, x_t)
    print(h.shape)
    print(h)
    print(y.shape)
    print(y)

# Expected Output
"""
Wh: [[ 1.76405235  0.40015721  0.97873798  2.2408932   1.86755799 -0.97727788
   0.95008842 -0.15135721 -0.10321885  0.4105985   0.14404357  1.45427351
   0.76103773  0.12167502  0.44386323]
 [ 0.33367433  1.49407907 -0.20515826  0.3130677  -0.85409574 -2.55298982
   0.6536186   0.8644362  -0.74216502  2.26975462 -1.45436567  0.04575852
  -0.18718385  1.53277921  1.46935877]
 [ 0.15494743  0.37816252 -0.88778575 -1.98079647 -0.34791215  0.15634897
   1.23029068  1.20237985 -0.38732682 -0.30230275 -1.04855297 -1.42001794
  -1.70627019  1.9507754  -0.50965218]
 [-0.4380743  -1.25279536  0.77749036 -1.61389785 -0.21274028 -0.89546656
   0.3869025  -0.51080514 -1.18063218 -0.02818223  0.42833187  0.06651722
   0.3024719  -0.63432209 -0.36274117]
 [-0.67246045 -0.35955316 -0.81314628 -1.7262826   0.17742614 -0.40178094
  -1.63019835  0.46278226 -0.90729836  0.0519454   0.72909056  0.12898291
   1.13940068 -1.23482582  0.40234164]
 [-0.68481009 -0.87079715 -0.57884966 -0.31155253  0.05616534 -1.16514984
   0.90082649  0.46566244 -1.53624369  1.48825219  1.89588918  1.17877957
  -0.17992484 -1.07075262  1.05445173]
 [-0.40317695  1.22244507  0.20827498  0.97663904  0.3563664   0.70657317
   0.01050002  1.78587049  0.12691209  0.40198936  1.8831507  -1.34775906
  -1.270485    0.96939671 -1.17312341]
 [ 1.94362119 -0.41361898 -0.74745481  1.92294203  1.48051479  1.86755896
   0.90604466 -0.86122569  1.91006495 -0.26800337  0.8024564   0.94725197
  -0.15501009  0.61407937  0.92220667]
 [ 0.37642553 -1.09940079  0.29823817  1.3263859  -0.69456786 -0.14963454
  -0.43515355  1.84926373  0.67229476  0.40746184 -0.76991607  0.53924919
  -0.67433266  0.03183056 -0.63584608]
 [ 0.67643329  0.57659082 -0.20829876  0.39600671 -1.09306151 -1.49125759
   0.4393917   0.1666735   0.63503144  2.38314477  0.94447949 -0.91282223
   1.11701629 -1.31590741 -0.4615846 ]
 [-0.06824161  1.71334272 -0.74475482 -0.82643854 -0.09845252 -0.66347829
   1.12663592 -1.07993151 -1.14746865 -0.43782004 -0.49803245  1.92953205
   0.94942081  0.08755124 -1.22543552]
 [ 0.84436298 -1.00021535 -1.5447711   1.18802979  0.31694261  0.92085882
   0.31872765  0.85683061 -0.65102559 -1.03424284  0.68159452 -0.80340966
  -0.68954978 -0.4555325   0.01747916]
 [-0.35399391 -1.37495129 -0.6436184  -2.22340315  0.62523145 -1.60205766
  -1.10438334  0.05216508 -0.739563    1.5430146  -1.29285691  0.26705087
  -0.03928282 -1.1680935   0.52327666]
 [-0.17154633  0.77179055  0.82350415  2.16323595  1.33652795 -0.36918184
  -0.23937918  1.0996596   0.65526373  0.64013153 -1.61695604 -0.02432612
  -0.73803091  0.2799246  -0.09815039]
 [ 0.91017891  0.31721822  0.78632796 -0.4664191  -0.94444626 -0.41004969
  -0.01702041  0.37915174  2.25930895 -0.04225715 -0.955945   -0.34598178
  -0.46359597  0.48148147 -1.54079701]
 [ 0.06326199  0.15650654  0.23218104 -0.59731607 -0.23792173 -1.42406091
  -0.49331988 -0.54286148  0.41605005 -1.15618243  0.7811981   1.49448454
  -2.06998503  0.42625873  0.67690804]
 [-0.63743703 -0.39727181 -0.13288058 -0.29779088 -0.30901297 -1.67600381
   1.15233156  1.07961859 -0.81336426 -1.46642433  0.52106488 -0.57578797
   0.14195316 -0.31932842  0.69153875]
 [ 0.69474914 -0.72559738 -1.38336396 -1.5829384   0.61037938 -1.18885926
  -0.50681635 -0.59631404 -0.0525673  -1.93627981  0.1887786   0.52389102
   0.08842209 -0.31088617  0.09740017]
 [ 0.39904635 -2.77259276  1.95591231  0.39009332 -0.65240858 -0.39095338
   0.49374178 -0.11610394 -2.03068447  2.06449286 -0.11054066  1.02017271
  -0.69204985  1.53637705  0.28634369]
 [ 0.60884383 -1.04525337  1.21114529  0.68981816  1.30184623 -0.62808756
  -0.48102712  2.3039167  -1.06001582 -0.1359497   1.13689136  0.09772497
   0.58295368 -0.39944903  0.37005589]
 [-1.30652685  1.65813068 -0.11816405 -0.6801782   0.66638308 -0.46071979
  -1.33425847 -1.34671751  0.69377315 -0.15957344 -0.13370156  1.07774381
  -1.12682581 -0.73067775 -0.38487981]
 [ 0.09435159 -0.04217145 -0.28688719 -0.0616264  -0.10730528 -0.71960439
  -0.81299299  0.27451636 -0.89091508 -1.15735526 -0.31229225 -0.15766702
   2.2567235  -0.70470028  0.94326072]
 [ 0.74718833 -1.18894496  0.77325298 -1.18388064 -2.65917224  0.60631952
  -1.75589058  0.45093446 -0.6840109   1.6595508   1.0685094  -0.4533858
  -0.68783761 -1.2140774  -0.44092263]
 [-0.2803555  -0.36469354  0.15670386  0.5785215   0.34965446 -0.76414392
  -1.43779147  1.36453185 -0.68944918 -0.6522936  -0.52118931 -1.84306955
  -0.477974   -0.47965581  0.6203583 ]
 [ 0.69845715  0.00377089  0.93184837  0.33996498 -0.01568211  0.16092817
  -0.19065349 -0.39484951 -0.26773354 -1.12801133  0.28044171 -0.99312361
   0.84163126 -0.24945858  0.04949498]]
Wy: [[ 0.49383678  0.64331447 -1.57062341 -0.20690368  0.88017891]
 [-1.69810582  0.38728048 -2.25556423 -1.02250684  0.03863055]
 [-1.6567151  -0.98551074 -1.47183501  1.64813493  0.16422776]
 [ 0.56729028 -0.2226751  -0.35343175 -1.61647419 -0.29183736]
 [-0.76149221  0.85792392  1.14110187  1.46657872  0.85255194]
 [-0.59865394 -1.11589699  0.76666318  0.35629282 -1.76853845]
 [ 0.35548179  0.81451982  0.05892559 -0.18505367 -0.80764849]
 [-1.4465347   0.80029795 -0.30911444 -0.23346666  1.73272119]
 [ 0.68450111  0.370825    0.14206181  1.51999486  1.71958931]
 [ 0.92950511  0.58222459 -2.09460307  0.12372191 -0.13010695]
 [ 0.09395323  0.94304609 -2.73967717 -0.56931205  0.26990435]
 [-0.46684555 -1.41690611  0.86896349  0.27687191 -0.97110457]
 [ 0.3148172   0.82158571  0.00529265  0.8005648   0.07826018]
 [-0.39522898 -1.15942052 -0.08593077  0.19429294  0.87583276]
 [-0.11510747  0.45741561 -0.96461201 -0.78262916 -0.1103893 ]]
bh: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
by: [[0. 0. 0. 0. 0.]]
(8, 15)
[[-0.99999848  0.99990248 -0.99996607 -0.99964416 -0.99988767  0.99908206
  -0.99245617  0.99774775  0.97661676 -0.99746223  0.99999904 -0.99058843
  -0.99202901 -0.99926176 -0.99999667]
 [-0.99268074  0.99986974 -0.9999067   0.26496763 -0.99999992  0.99365559
   0.99997865 -0.92923321  0.9999915   0.99999973 -0.99999416 -0.99999998
   0.99883056  0.99975776 -0.93935595]
 [-0.36902575  0.44492003 -0.99944275 -0.99995563 -0.99992097  0.99665852
   0.72379803 -0.99999326 -0.99999954  0.94773029 -0.97691994 -0.99977637
   0.99980692 -0.67651382 -0.99156369]
 [-0.39806064 -0.99999418 -0.99310123 -1.         -1.         -0.98585334
  -0.99999405 -0.86267795 -0.99999684  0.99762024  0.51839154 -0.99999769
   0.83558747 -0.9998692   0.58947407]
 [-0.99993686  0.99998677  0.81137977 -0.99854303 -0.99556855  0.99953662
  -0.85555078 -0.98745137  0.99413322 -0.85880888 -0.99999992 -0.99999995
  -0.99997633  0.99973741 -0.99869053]
 [-0.9950876   0.99994904 -0.25654338 -0.99954077 -0.90971218 -0.99698643
   0.89590124 -1.         -0.75081061 -0.99999017  0.96185436  0.99998106
   1.         -0.99885591  0.99871836]
 [ 0.99900693  0.99999998  0.99868214  1.          0.99999998  0.95036811
   0.98572661 -0.99999124  0.99999997  0.99999834 -0.99994008  0.99999994
  -0.84676252  0.9999987  -0.95978065]
 [-0.99696688 -0.999886    0.04534836 -0.9992306  -0.9739127   1.
  -0.99999982 -0.99999987 -0.99974037  0.55317951 -0.66867349  0.67942504
   0.99999786 -0.99988625 -0.70956345]]
(8, 5)
[[1.50328186e-01 1.29400413e-01 6.14354644e-02 2.35274383e-03
  6.56483193e-01]
 [9.94092370e-01 5.87047609e-04 4.90027791e-03 2.00413513e-04
  2.19891436e-04]
 [9.85207589e-01 2.78196514e-03 1.18935976e-02 1.11375379e-04
  5.47286326e-06]
 [9.97514909e-01 2.42656583e-03 1.15037301e-05 1.89191768e-06
  4.51297575e-05]
 [3.54722882e-02 4.82841223e-05 7.08650891e-01 2.04258139e-01
  5.15703974e-02]
 [7.82585179e-01 2.08891987e-01 6.72865883e-03 6.11072148e-04
  1.18310327e-03]
 [4.50921405e-01 9.84190850e-04 2.73752410e-02 4.67680649e-01
  5.30385145e-02]
 [3.37730695e-01 1.84532669e-05 6.57162397e-01 5.08562982e-03
  2.82459439e-06]]
  """
